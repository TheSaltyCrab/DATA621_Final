---
title: "Final assignment group 4"
author: Deepika Dilip, Tora Mullings, Daniel Sullivan, Deepa Sharma, Bikram Barua,
  Newman Okereafor
date: '2022-11-24'
output: 
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
```

```{r}
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrplot)
library(reshape2)
library(knitr)
library(broom)
library(caret)
library(leaps)
library(MASS)
library(magrittr)
library(betareg)
library(pscl)
library(gtsummary)
library(nnet)
library(readr)
library(fastDummies)
library(ComplexHeatmap)
library(kableExtra)
library(xgboost)
```


# Abstract:

Maternal mortality is a leading public health issue in Bangladesh, with [173 deaths per 100k births](https://www.macrotrends.net/countries/BGD/bangladesh/maternal-mortality-rate). Yet with improvements in public health surveillance, a preventative responsive could be better informed with biomarker data and accurate risk predictions. For this project, we utilize multinomial models to quantify the contribution of biomarkers in predicting mortality risk.

# Key words:

maternal health, clinical outcomes

# Introduction:

Maternal mortality is a leading public health issue in Bangladesh. Advances in public health outreach and medical pipelines have reduced maternal mortality rates, but there remains a glaring gap, especially when considering additional factors, such as socioeconomic status. One of the [WHO Sustainable Development Goals](https://www.who.int/data/gho/data/themes/topics/indicator-groups/indicator-group-details/GHO/maternal-mortality) was to reduce the global mortality ratio to less than 70 deaths per 100k births 

Here, we further explore mortality risk as a product of standard clinical indicators.  We obtained this dataset from the [UCI repository](https://archive.ics.uci.edu/ml/datasets/Maternal+Health+Risk+Data+Set). Data was aggregated from different sites, including rural and urban health centers.

# Literature review:

Previous studies on maternal health present the following key findings:

* 
* 
* 


# Methodology:

## Exploratory Data Analysis:

```{r}
MHRD<-read.csv("https://raw.githubusercontent.com/TheSaltyCrab/DATA621_Final/main/Maternal%20Health%20Risk%20Data%20Set.csv")
```


```{r}
head(MHRD,5) %>% kable()
```

### Data Attributes

* `Age`: Any ages in years when a women during pregnant.

* `SystolicBP`: Upper value of Blood Pressure in mmHg, another significant attribute during pregnancy.

* `DiastolicBP`: Lower value of Blood Pressure in mmHg, another significant attribute during pregnancy.

* `BS`: Blood glucose levels is in terms of a molar concentration, mmol/L.

* `HeartRate`: A normal resting heart rate in beats per minute.

* `Risk Level`: Predicted Risk Intensity Level during pregnancy considering the previous attribute.

```{r}
# MHRD<-MHRD%>% mutate(Risk_num = case_when(
#     str_detect(.$RiskLevel, "low risk") ~ "0",
#     str_detect(.$RiskLevel, "mid risk") ~ "1",
#     str_detect(.$RiskLevel, "high risk") ~ "2",
#     TRUE ~ as.character(.$RiskLevel)))
MHRD = MHRD %>% mutate(RiskLevel = factor(RiskLevel, levels = c("low risk", "mid risk", "high risk")))

```

We can start by making a correlation plot to compare continuous values. Age is positively correlated with systolic and diastolic blood pressure. 

```{r}
corrplot(cor( select_if(MHRD, is.numeric), use = "complete.obs"), tl.col="black", tl.cex=0.6, order='AOE')
```

The first step is visualizing data distribution by risk. Here we can see age is skewed, and the extremities of blood pressure and glucose levels are flagged as high risk.

```{r}
lst.histogram = list()
for (i in names(MHRD)[1:6]) {
  MHRD.sub = MHRD %>% select(i, "RiskLevel")
  colnames(MHRD.sub) = c("value", "RiskLevel")
  lst.histogram[[i]] = ggplot(aes(value, fill = RiskLevel), data = MHRD.sub) + geom_histogram() + labs(x = i, y = "Count") + scale_fill_manual(values = c("low risk" = "navyblue", "mid risk" = "grey", "high risk" = "red"))
}
ggpubr::ggarrange(plotlist = lst.histogram, ncol = 2, nrow = 3)
```

```{r}
ggplot(aes(RiskLevel, fill = RiskLevel), data = MHRD) + geom_bar(stat = "count") + labs(x = "Risk Level", y = "Count") + scale_fill_manual(values = c("low risk" = "navyblue", "mid risk" = "grey", "high risk" = "red")) + labs(title = "Risk Level Counts")
```

One approach we can take is implementing unsupervised clustering since many of the biomarkers are continuous. We can do this by forming a matrix of indicators and seeing if risk levels clusters. From this analysis, we see 6 distinct subgroups: 2 high risk, 3 low risk, and 1 mid risk (with some heterogeneity).

```{r}
mat.MHRD = MHRD %>% select(-c("RiskLevel")) %>% as.matrix()
rownames(mat.MHRD) = rownames(MHRD)
mat.MHRD = t(mat.MHRD)
tree = hclust(dist(t(mat.MHRD), method = "euclidean"))
tree.groups = cutree(hclust(dist(t(mat.MHRD), method = "euclidean")), k = 6)

mat.risk = MHRD %>% select(c("RiskLevel")) %>% as.matrix()
Heatmap(t(mat.risk), cluster_columns  = tree, cluster_rows = F, col =c("low risk" = "navyblue", "mid risk" = "grey", "high risk" = "red"),  heatmap_height = unit(2, "cm"), column_split = 6, name = "Risk")
```

## Multinomial Regression 

First we partitioned the dataset using a 70-30 split. We initially fit a full model with all included variables as predictors. Next, we fit a series of multinomial models, starting with a full model. We then implemented feature selection based on statistical significance to improve accuracy.

```{r}
set.seed(100)
trainingRows <- sample(1:nrow(MHRD), 0.7*nrow(MHRD))
training <- MHRD[trainingRows, ]
test <- MHRD[-trainingRows, ]
```

## XGBoost

We also decided to try using a model that combined previous models with new ones, subsequently increasing accuracy. Therefore, we decided to fit the eXtreme Gradient Boosting algorthim from the `xgboost` package. In this case, however, we have to split our outcome: one model with predict high risk while the other will predict medium risk.

# Results



## Full Model:

### Resulting Coefficients:

```{r}
mn_model<-multinom(RiskLevel ~ ., data=training, trace = F)
data.frame(summary(mn_model)$coefficients/summary(mn_model)$standard.errors) %>% kable() %>% kableExtra::kable_styling(full_width = F) 

```


### Confusion Matrix:
```{r}
predicted_scores <- predict (mn_model, test, "probs")
predicted_class <- predict (mn_model, test)
#table(predicted_class,test$RiskLevel)
#mean(as.character(predicted_class) != as.character(test$RiskLevel))

t(confusionMatrix(data = predicted_class, reference = test$RiskLevel)$byClass) %>% knitr::kable()

```


## Age and Systolic BP as Predictors: 

### Model Coefficients
```{r}
mn_model2<-multinom(RiskLevel ~ Age + SystolicBP + BS, data=training, trace = F)
# summary(mn_model2)
data.frame(summary(mn_model2)$coefficients/summary(mn_model2)$standard.errors) %>% kable() 

```

### Confusion Matrix
```{r}

predicted_scores2 <- predict (mn_model2, test, "probs")
predicted_class2 <- predict (mn_model2, test)
# table(predicted_class2,test$RiskLevel)

t(confusionMatrix(data = predicted_class2, reference = test$RiskLevel)$byClass) %>% knitr::kable()
```


## Blood Sugar and Systolic BP as Predictors: 

### Model Coefficients:

```{r}
mn_model3 <-multinom(RiskLevel ~ BS+SystolicBP, data=training, trace = F)
# summary(mn_model3)

data.frame(summary(mn_model3)$coefficients/summary(mn_model3)$standard.errors) %>% kable() 

#mean(as.character(predicted_class3) != as.character(test$RiskLevel))

```

### Confusion Matrix:
```{r}

predicted_scores3 <- predict (mn_model3, test, "probs")
predicted_class3 <- predict (mn_model3, test)
#table(predicted_class3,test$RiskLevel)
t(confusionMatrix(data = predicted_class3, reference = test$RiskLevel)$byClass) %>% knitr::kable()
```


## Blood Sugar as Predictor: 

### Coefficients:
```{r, echo = F, message = F}
mn_model4<-multinom(RiskLevel ~ BS, data=training, trace = F)
# summary(mn_model4)
data.frame(summary(mn_model4)$coefficients/summary(mn_model4)$standard.errors) %>% kable() 

```

### Confusion Matrix:
```{r}
predicted_scores4 <- predict (mn_model4, test, "probs")
predicted_class4 <- predict (mn_model4, test)
data.frame(summary(mn_model4)$coefficients/summary(mn_model4)$standard.errors) %>% kable() 
t(confusionMatrix(data = predicted_class4, reference = test$RiskLevel)$byClass) %>% knitr::kable()
```

## XGBoost Model


### Predicting High Risk

```{r}
xboost.dat = training
xboost.dat = xboost.dat %>% mutate(high_risk = ifelse(RiskLevel == "high risk", T, F))
xboost.dat = xboost.dat %>% mutate(mid_risk = ifelse(RiskLevel == "mid risk", T, F))

xboost.dat.test = test

xboost.dat.test = xboost.dat.test %>% mutate(high_risk = ifelse(RiskLevel == "high risk", T, F))
xboost.dat.test = xboost.dat.test %>% mutate(mid_risk = ifelse(RiskLevel == "mid risk", T, F))


grid_default <- expand.grid(
  nrounds = 100,
  max_depth = 6,
  eta = 0.3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

train_control <- caret::trainControl(
  method = "none",
  verboseIter = FALSE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

xgb_train_high <- caret::train( x = select(xboost.dat.test, -c("RiskLevel", "high_risk", "mid_risk")),
  y = as.numeric(xboost.dat.test$high_risk),
  trControl = train_control,
  tuneGrid = grid_default,
  method = "xgbTree",
  verbose = TRUE
)

xgb_train_mid <- caret::train( x = select(xboost.dat.test, -c("RiskLevel", "high_risk", "mid_risk")),
  y = as.numeric(xboost.dat.test$mid_risk),
  trControl = train_control,
  tuneGrid = grid_default,
  method = "xgbTree",
  verbose = TRUE
)

pred.high <- predict(xgb_train_high, select(xboost.dat.test, -c("RiskLevel", "high_risk", "mid_risk")))

vec.pred.high = c(pred.high > 0.5)

(confusionMatrix(data = factor(vec.pred.high), reference = factor(xboost.dat.test$high_risk))$byClass) %>% knitr::kable()


# 
# dtrain.high <- xgb.DMatrix(data = as.matrix(select(xboost.dat, -c("RiskLevel", "high_risk", "low_risk"))), label= unlist(xboost.dat$high_risk))
# 
# dtest.high <- xgb.DMatrix(data = as.matrix(select(xboost.dat.test, -c("RiskLevel", "high_risk", "low_risk"))), label= unlist(xboost.dat.test$high_risk))
# 
# dtest.low<- xgb.DMatrix(data = as.matrix(select(xboost.dat.test, -c("RiskLevel", "high_risk", "low_risk"))), label= unlist(xboost.dat.test$low_risk))
# 
# 
# dtrain.low <- xgb.DMatrix(data = as.matrix(select(xboost.dat, -c("RiskLevel", "high_risk", "low_risk"))), label= unlist(xboost.dat$low_risk))
# 
# 
# xboost.high <- xgboost(data = dtrain.high, # the data   
#                  nround = 2, # max number of boosting iterations
#                  objective = "binary:logistic")  # the objective function
# 
# 
# xboost.low <- xgboost(data = dtrain.low, # the data   
#                  nround = 2, # max number of boosting iterations
#                  objective = "binary:logistic")  # the objective function
# 
# pred.high <- predict(xboost.high, dtest.high)

```

### Predicting Medium Risk
```{r}

pred.mid <- predict(xgb_train_mid, select(xboost.dat.test, -c("RiskLevel", "high_risk", "mid_risk")))

vec.pred.mid = c(pred.mid > 0.5)

(confusionMatrix(data = factor(vec.pred.mid), reference = factor(xboost.dat.test$mid_risk))$byClass) %>% knitr::kable()
```


# Discussion and Conclusions:

## Model Interpretation:
First we take a look into multinomial model assessing the accuracy of all predictors and pairing things down to try and improve the model. Starting with the every variable the multinomial model gives a miss error of 41% which is not great. from here we eliminated redundant as well as with low correlation values to the class level. This did not work out as planned. The first paired down model consisting of Age, Systolic blood pressure, and Blood sugar showed an even worse error rate around 44%. pared down more with blood sugar and systolic blood pressure the missclassification was around 48% and the only improvement was upon making a model solely with blood sugar when the error rate dropped to 40%. I believe that this shows the multinomial regression clearly does not reflect or predict the data too well. One potential future for this type of model would be a boosted multinomial model to help improve accuracy of predictions. 


# References: 

Be sure to cite all references used in the report (APA format).

#   Appendices:
#	Supplemental tables and/or figures.
#	R statistical programming code.
